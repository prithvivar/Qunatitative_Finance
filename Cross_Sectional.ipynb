{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba87857b-080e-49f2-bb8e-e1dddd17b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports and display options\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.width\", 140)\n",
    "pd.set_option(\"display.max_columns\", 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae0ef51-f889-400d-bf5c-cde5a893dbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date     asset       value        item\n",
      "0    2020-01-01    ADAUSD    0.033813  daily_high\n",
      "1450 2020-01-01  LINK-USD -999.000000   daily_ret\n",
      "1449 2020-01-01   ETH-USD -999.000000   daily_ret\n",
      "1448 2020-01-01   BTC-USD -999.000000   daily_ret\n",
      "2895 2020-01-01   ADA-USD    0.032704   daily_low\n",
      "\n",
      "Items: ['daily_high' 'daily_ret' 'daily_low']\n",
      "Assets: ['ADAUSD' 'LINK-USD' 'ETH-USD' 'BTC-USD' 'ADA-USD' 'LINKUSD' 'ETHUSD'\n",
      " 'BTCUSD']\n",
      "\n",
      "Shapes:\n",
      "ret_raw : (362, 4)\n",
      "high_raw: (362, 4)\n",
      "low_raw : (271, 4)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "\n",
    "df = pd.read_pickle(\"/Users/prithvivarman/Desktop/Projects/TWSQ DataProject 2/DataProject.pk\")\n",
    "\n",
    "# Ensure date is datetime and sorted\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\nItems:\", df[\"item\"].unique())\n",
    "print(\"Assets:\", df[\"asset\"].unique())\n",
    "\n",
    "# --- Pivot each item separately ---\n",
    "\n",
    "# Returns\n",
    "ret_raw = (\n",
    "    df[df[\"item\"] == \"daily_ret\"]\n",
    "    .pivot_table(index=\"date\", columns=\"asset\", values=\"value\")\n",
    ")\n",
    "\n",
    "# Highs\n",
    "high_raw = (\n",
    "    df[df[\"item\"] == \"daily_high\"]\n",
    "    .pivot_table(index=\"date\", columns=\"asset\", values=\"value\")\n",
    ")\n",
    "\n",
    "# Lows\n",
    "low_raw = (\n",
    "    df[df[\"item\"] == \"daily_low\"]\n",
    "    .pivot_table(index=\"date\", columns=\"asset\", values=\"value\")\n",
    ")\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"ret_raw :\", ret_raw.shape)\n",
    "print(\"high_raw:\", high_raw.shape)\n",
    "print(\"low_raw :\", low_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58afd9e-2f02-4215-be39-99c080010dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned high shape: (271, 0)\n",
      "Aligned low  shape: (271, 0)\n",
      "Number of dates with high < low: 0\n",
      "\n",
      "Clean return matrix shape: (270, 4)\n",
      "Clean date range: 2020-01-02 00:00:00 to 2020-12-31 00:00:00\n",
      "Assets: ['ADA-USD', 'BTC-USD', 'ETH-USD', 'LINK-USD']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: clean data\n",
    "\n",
    "# 3.1 Align high and low so indices & columns match\n",
    "high_aligned, low_aligned = high_raw.align(low_raw, join=\"inner\")\n",
    "\n",
    "print(\"Aligned high shape:\", high_aligned.shape)\n",
    "print(\"Aligned low  shape:\", low_aligned.shape)\n",
    "\n",
    "# 3.2 Sanity check: high should not be below low\n",
    "bad_mask = (high_aligned < low_aligned)\n",
    "bad_dates = bad_mask.any(axis=1)\n",
    "\n",
    "print(\"Number of dates with high < low:\", bad_dates.sum())\n",
    "if bad_dates.sum() > 0:\n",
    "    print(\"Example problematic dates:\", bad_dates[bad_dates].index[:5])\n",
    "\n",
    "# Drop bad dates from all series (returns + high + low)\n",
    "good_dates = high_aligned.index[~bad_dates]\n",
    "ret_clean = ret_raw.loc[good_dates].copy()\n",
    "\n",
    "# 3.3 Drop dates with any missing returns (avoid partial cross-section)\n",
    "ret_clean = ret_clean.dropna(how=\"any\")\n",
    "\n",
    "print(\"\\nClean return matrix shape:\", ret_clean.shape)\n",
    "print(\"Clean date range:\", ret_clean.index.min(), \"to\", ret_clean.index.max())\n",
    "print(\"Assets:\", list(ret_clean.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b75e61b-03e4-40c1-ab39-b357b582d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: summarise performance from a daily return series\n",
    "\n",
    "def summarize_performance(port_ret, name=\"strategy\"):\n",
    "    port_ret = port_ret.dropna()\n",
    "    n = len(port_ret)\n",
    "    if n == 0:\n",
    "        print(f\"{name}: no data\")\n",
    "        return {}\n",
    "\n",
    "    mean_daily = port_ret.mean()\n",
    "    vol_daily  = port_ret.std(ddof=1)\n",
    "    sharpe_daily = mean_daily / vol_daily if vol_daily != 0 else np.nan\n",
    "\n",
    "    mean_annual   = mean_daily * 252\n",
    "    vol_annual    = vol_daily * np.sqrt(252)\n",
    "    sharpe_annual = sharpe_daily * np.sqrt(252)\n",
    "\n",
    "    # t-stat for mean > 0\n",
    "    t_stat = mean_daily / (vol_daily / np.sqrt(n)) if vol_daily != 0 else np.nan\n",
    "\n",
    "    # Drawdown and duration\n",
    "    equity = (1 + port_ret).cumprod()\n",
    "    running_max = equity.cummax()\n",
    "    drawdown = equity / running_max - 1.0\n",
    "    max_dd = drawdown.min()\n",
    "\n",
    "    underwater = equity < running_max\n",
    "    max_duration = 0\n",
    "    current = 0\n",
    "    for flag in underwater:\n",
    "        if flag:\n",
    "            current += 1\n",
    "            max_duration = max(max_duration, current)\n",
    "        else:\n",
    "            current = 0\n",
    "\n",
    "    stats = {\n",
    "        \"name\": name,\n",
    "        \"n_days\": n,\n",
    "        \"mean_daily\": mean_daily,\n",
    "        \"vol_daily\": vol_daily,\n",
    "        \"sharpe_daily\": sharpe_daily,\n",
    "        \"mean_annual\": mean_annual,\n",
    "        \"vol_annual\": vol_annual,\n",
    "        \"sharpe_annual\": sharpe_annual,\n",
    "        \"t_stat\": t_stat,\n",
    "        \"max_dd\": max_dd,\n",
    "        \"max_dd_days\": max_duration,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    for k, v in stats.items():\n",
    "        if k == \"name\":\n",
    "            continue\n",
    "        print(f\"{k:15s}: {v}\")\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9811523e-d3bf-4d64-980c-b517f6141107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: cross-sectional momentum backtest (with costs & date window)\n",
    "\n",
    "def backtest_cs_mom(\n",
    "    ret_df,\n",
    "    lookback=20,\n",
    "    n_long=2,\n",
    "    n_short=2,\n",
    "    cost_bps=0.001,   # 10 bps per unit of turnover\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Cross-sectional momentum: long n_long winners, short n_short losers.\n",
    "\n",
    "    ret_df   : DataFrame of daily returns (rows: dates, cols: assets)\n",
    "    lookback : number of days used to compute momentum (rolling sum)\n",
    "    n_long   : number of top assets to long\n",
    "    n_short  : number of bottom assets to short\n",
    "    cost_bps : proportional one-way transaction cost per unit of weight change\n",
    "               e.g. 0.001 = 10 bps (0.10%) per unit of turnover\n",
    "    start_date, end_date : date window for evaluation (out-of-sample)\n",
    "                           earlier data are still used to compute momentum.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 1. Set evaluation window ----\n",
    "    all_dates = ret_df.index\n",
    "    if start_date is None:\n",
    "        start_date = all_dates.min()\n",
    "    if end_date is None:\n",
    "        end_date = all_dates.max()\n",
    "\n",
    "    # We need data up to end_date to compute signals\n",
    "    sub = ret_df.loc[:end_date].copy()\n",
    "\n",
    "    # ---- 2. Momentum signal: rolling sum over past 'lookback' days ----\n",
    "    # Mom_t,i = sum_{k=1..lookback} r_{t-k,i}\n",
    "    mom = sub.rolling(window=lookback).sum()\n",
    "\n",
    "    assets = sub.columns\n",
    "    n_assets = len(assets)\n",
    "\n",
    "    # ---- 3. Raw target weights each day based on cross-sectional rank ----\n",
    "    weights_raw = pd.DataFrame(index=sub.index, columns=assets, data=0.0)\n",
    "\n",
    "    for dt in sub.index:\n",
    "        sig = mom.loc[dt]\n",
    "\n",
    "        if sig.isna().all():\n",
    "            continue\n",
    "\n",
    "        sig = sig.dropna()\n",
    "        if len(sig) == 0:\n",
    "            continue\n",
    "\n",
    "        sig_sorted = sig.sort_values(ascending=False)\n",
    "\n",
    "        n_long_eff  = min(n_long,  len(sig_sorted))\n",
    "        n_short_eff = min(n_short, len(sig_sorted) - n_long_eff)\n",
    "\n",
    "        long_assets  = sig_sorted.index[:n_long_eff]\n",
    "        short_assets = sig_sorted.index[-n_short_eff:] if n_short_eff > 0 else []\n",
    "\n",
    "        long_weight  =  0.5 / n_long_eff if n_long_eff > 0 else 0.0\n",
    "        short_weight = -0.5 / n_short_eff if n_short_eff > 0 else 0.0\n",
    "\n",
    "        for a in long_assets:\n",
    "            weights_raw.loc[dt, a] = long_weight\n",
    "        for a in short_assets:\n",
    "            weights_raw.loc[dt, a] = short_weight\n",
    "\n",
    "    # ---- 4. Transaction costs ----\n",
    "    # Turnover_t = sum_i |w_raw_t,i - w_raw_{t-1,i}|\n",
    "    weights_prev = weights_raw.shift(1)\n",
    "    turnover = (weights_raw - weights_prev).abs().sum(axis=1).fillna(0.0)\n",
    "    tc = cost_bps * turnover  # cost as a daily return\n",
    "\n",
    "    # ---- 5. Portfolio returns (no look-ahead) ----\n",
    "    # Use yesterday's weights on today's returns\n",
    "    gross_ret = (weights_prev * sub).sum(axis=1)\n",
    "\n",
    "    # Net return after transaction cost\n",
    "    net_ret = gross_ret - tc\n",
    "\n",
    "    # ---- 6. Restrict to evaluation window ----\n",
    "    net_ret = net_ret.loc[start_date:end_date]\n",
    "\n",
    "    if name is None:\n",
    "        name = f\"CS_MOM_L{lookback}_L{n_long}_S{n_short}\"\n",
    "\n",
    "    stats = summarize_performance(net_ret, name=name)\n",
    "    return net_ret, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4bd8009-b313-448a-b4df-6a2eb86c2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train window : 2020-01-02 00:00:00 to 2020-10-10 00:00:00\n",
      "Test window  : 2020-10-11 00:00:00 to 2020-12-31 00:00:00\n",
      "Total days   : 270 (train: 190 , test: 80 )\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: define train / test windows\n",
    "\n",
    "dates = ret_clean.index\n",
    "n_dates = len(dates)\n",
    "\n",
    "split_idx = int(n_dates * 0.7)  # 70% train, 30% test\n",
    "\n",
    "train_start = dates[0]\n",
    "train_end   = dates[split_idx]\n",
    "test_start  = dates[split_idx + 1] if split_idx + 1 < n_dates else dates[-1]\n",
    "test_end    = dates[-1]\n",
    "\n",
    "print(\"Train window :\", train_start, \"to\", train_end)\n",
    "print(\"Test window  :\", test_start,  \"to\", test_end)\n",
    "print(\"Total days   :\", n_dates, \"(train:\", split_idx + 1, \", test:\", n_dates - (split_idx + 1), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93ae0b0b-6a87-4636-87c6-b8e7ebe20c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN_L5_Long1_Short1 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 302.33103915351336\n",
      "vol_daily      : 244.7980083408731\n",
      "sharpe_daily   : 1.235022462815659\n",
      "mean_annual    : 76187.42186668537\n",
      "vol_annual     : 3886.047909083194\n",
      "sharpe_annual  : 19.605373801132497\n",
      "t_stat         : 17.023609837377577\n",
      "max_dd         : -0.0010000000000000009\n",
      "max_dd_days    : 1\n",
      "\n",
      "=== TRAIN_L5_Long2_Short2 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 190.59896359259758\n",
      "vol_daily      : 176.45215177840615\n",
      "sharpe_daily   : 1.0801736429485849\n",
      "mean_annual    : 48030.93882533459\n",
      "vol_annual     : 2801.0910714473175\n",
      "sharpe_annual  : 17.1472249920518\n",
      "t_stat         : 14.889166155126189\n",
      "max_dd         : -0.09944395881562385\n",
      "max_dd_days    : 64\n",
      "\n",
      "=== TRAIN_L10_Long1_Short1 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 289.18634932694664\n",
      "vol_daily      : 247.27024081011436\n",
      "sharpe_daily   : 1.1695153787188681\n",
      "mean_annual    : 72874.96003039055\n",
      "vol_annual     : 3925.293382863703\n",
      "sharpe_annual  : 18.565481079333882\n",
      "t_stat         : 16.120656996580138\n",
      "max_dd         : -0.13130482143370092\n",
      "max_dd_days    : 36\n",
      "\n",
      "=== TRAIN_L10_Long2_Short2 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 184.0275230306766\n",
      "vol_daily      : 178.77438747414914\n",
      "sharpe_daily   : 1.0293841619638444\n",
      "mean_annual    : 46374.93580373051\n",
      "vol_annual     : 2837.955420266995\n",
      "sharpe_annual  : 16.340966976629797\n",
      "t_stat         : 14.189081473139167\n",
      "max_dd         : -0.057091578726912395\n",
      "max_dd_days    : 23\n",
      "\n",
      "=== TRAIN_L20_Long1_Short1 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 262.89619882851423\n",
      "vol_daily      : 250.06346283800397\n",
      "sharpe_daily   : 1.0513179168394686\n",
      "mean_annual    : 66249.84210478558\n",
      "vol_annual     : 3969.6344079180035\n",
      "sharpe_annual  : 16.68915454094231\n",
      "t_stat         : 14.491417419661168\n",
      "max_dd         : -0.10175020237446197\n",
      "max_dd_days    : 36\n",
      "\n",
      "=== TRAIN_L20_Long2_Short2 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 170.88255807503708\n",
      "vol_daily      : 182.61926343062964\n",
      "sharpe_daily   : 0.9357312852154236\n",
      "mean_annual    : 43062.40463490935\n",
      "vol_annual     : 2898.9909338834295\n",
      "sharpe_annual  : 14.854273647977168\n",
      "t_stat         : 12.898165654265439\n",
      "max_dd         : -0.045890929252063284\n",
      "max_dd_days    : 28\n",
      "\n",
      "=== TRAIN_L40_Long1_Short1 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 210.31684792840105\n",
      "vol_daily      : 247.26690065769085\n",
      "sharpe_daily   : 0.8505661185099643\n",
      "mean_annual    : 52999.84567795706\n",
      "vol_annual     : 3925.240359587781\n",
      "sharpe_annual  : 13.50231853916915\n",
      "t_stat         : 11.724244844417496\n",
      "max_dd         : -0.051114110712386585\n",
      "max_dd_days    : 24\n",
      "\n",
      "=== TRAIN_L40_Long2_Short2 ===\n",
      "n_days         : 190\n",
      "mean_daily     : 131.44741330825843\n",
      "vol_daily      : 169.804636397221\n",
      "sharpe_daily   : 0.774109683323168\n",
      "mean_annual    : 33124.748153681125\n",
      "vol_annual     : 2695.5650362367614\n",
      "sharpe_annual  : 12.288610257360402\n",
      "t_stat         : 10.670365614391669\n",
      "max_dd         : -0.06027515674883355\n",
      "max_dd_days    : 35\n",
      "\n",
      "=== Training results (sorted by Sharpe) ===\n",
      "                     name  lookback  n_long  n_short  sharpe_annual   mean_annual   vol_annual    max_dd  max_dd_days\n",
      "0   TRAIN_L5_Long1_Short1         5       1        1      19.605374  76187.421867  3886.047909 -0.001000            1\n",
      "2  TRAIN_L10_Long1_Short1        10       1        1      18.565481  72874.960030  3925.293383 -0.131305           36\n",
      "1   TRAIN_L5_Long2_Short2         5       2        2      17.147225  48030.938825  2801.091071 -0.099444           64\n",
      "4  TRAIN_L20_Long1_Short1        20       1        1      16.689155  66249.842105  3969.634408 -0.101750           36\n",
      "3  TRAIN_L10_Long2_Short2        10       2        2      16.340967  46374.935804  2837.955420 -0.057092           23\n",
      "5  TRAIN_L20_Long2_Short2        20       2        2      14.854274  43062.404635  2898.990934 -0.045891           28\n",
      "6  TRAIN_L40_Long1_Short1        40       1        1      13.502319  52999.845678  3925.240360 -0.051114           24\n",
      "7  TRAIN_L40_Long2_Short2        40       2        2      12.288610  33124.748154  2695.565036 -0.060275           35\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” NEW Cell 7: parameter grid search on TRAINING window only (fixed)\n",
    "\n",
    "results_train = []\n",
    "\n",
    "lookbacks = [5, 10, 20, 40]          # you can change these\n",
    "long_short_pairs = [(1, 1), (2, 2)]  # 1 long/1 short vs 2 long/2 short\n",
    "\n",
    "for L in lookbacks:\n",
    "    for (nL, nS) in long_short_pairs:\n",
    "        name = f\"TRAIN_L{L}_Long{nL}_Short{nS}\"\n",
    "        net_ret_train, stats_train = backtest_cs_mom(\n",
    "            ret_clean,\n",
    "            lookback=L,\n",
    "            n_long=nL,\n",
    "            n_short=nS,\n",
    "            cost_bps=0.001,          # 10 bps per unit turnover\n",
    "            start_date=train_start,\n",
    "            end_date=train_end,\n",
    "            name=name\n",
    "        )\n",
    "\n",
    "        # ðŸ”´ IMPORTANT: attach the parameters to the stats dict\n",
    "        stats_train[\"lookback\"] = L\n",
    "        stats_train[\"n_long\"]   = nL\n",
    "        stats_train[\"n_short\"]  = nS\n",
    "\n",
    "        results_train.append(stats_train)\n",
    "\n",
    "# Build DataFrame with both performance + parameter info\n",
    "train_df = pd.DataFrame(results_train)\n",
    "\n",
    "cols_show = [\n",
    "    \"name\",\n",
    "    \"lookback\",\n",
    "    \"n_long\",\n",
    "    \"n_short\",\n",
    "    \"sharpe_annual\",\n",
    "    \"mean_annual\",\n",
    "    \"vol_annual\",\n",
    "    \"max_dd\",\n",
    "    \"max_dd_days\",\n",
    "]\n",
    "\n",
    "print(\"\\n=== Training results (sorted by Sharpe) ===\")\n",
    "print(train_df[cols_show].sort_values(\"sharpe_annual\", ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0551f68-2c02-4884-a8d8-cdfbc6521bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best training config:\n",
      "Row index: 0\n",
      "Lookback : 5\n",
      "n_long   : 1\n",
      "n_short  : 1\n",
      "Train Sharpe: 19.605373801132497\n",
      "\n",
      "=== BEST_TRAIN ===\n",
      "n_days         : 190\n",
      "mean_daily     : 302.33103915351336\n",
      "vol_daily      : 244.7980083408731\n",
      "sharpe_daily   : 1.235022462815659\n",
      "mean_annual    : 76187.42186668537\n",
      "vol_annual     : 3886.047909083194\n",
      "sharpe_annual  : 19.605373801132497\n",
      "t_stat         : 17.023609837377577\n",
      "max_dd         : -0.0010000000000000009\n",
      "max_dd_days    : 1\n",
      "\n",
      "=== BEST_TEST ===\n",
      "n_days         : 80\n",
      "mean_daily     : 0.002245547278936355\n",
      "vol_daily      : 0.02233007884394921\n",
      "sharpe_daily   : 0.10056154725780701\n",
      "mean_annual    : 0.5658779142919614\n",
      "vol_annual     : 0.3544790122653258\n",
      "sharpe_annual  : 1.5963650730001602\n",
      "t_stat         : 0.8994498223640562\n",
      "max_dd         : -0.11540536516715239\n",
      "max_dd_days    : 24\n",
      "\n",
      "=== BEST_FULL ===\n",
      "n_days         : 270\n",
      "mean_daily     : 212.75213734425873\n",
      "vol_daily      : 247.45289629724957\n",
      "sharpe_daily   : 0.8597682246915106\n",
      "mean_annual    : 53613.538610753196\n",
      "vol_annual     : 3928.1929488310693\n",
      "sharpe_annual  : 13.648397446135439\n",
      "t_stat         : 14.127433526691314\n",
      "max_dd         : -0.0010000000000000009\n",
      "max_dd_days    : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” NEW Cell 8: choose best training config, then evaluate on TRAIN and TEST (fixed)\n",
    "\n",
    "# 8.1 Pick best params based on training Sharpe\n",
    "best_idx = train_df[\"sharpe_annual\"].idxmax()\n",
    "best_row = train_df.loc[best_idx]\n",
    "\n",
    "best_lookback = int(best_row[\"lookback\"])\n",
    "best_n_long   = int(best_row[\"n_long\"])\n",
    "best_n_short  = int(best_row[\"n_short\"])\n",
    "\n",
    "print(\"\\nBest training config:\")\n",
    "print(\"Row index:\", best_idx)\n",
    "print(\"Lookback :\", best_lookback)\n",
    "print(\"n_long   :\", best_n_long)\n",
    "print(\"n_short  :\", best_n_short)\n",
    "print(\"Train Sharpe:\", best_row[\"sharpe_annual\"])\n",
    "\n",
    "# 8.2 Re-run on TRAIN window (for a clean summary)\n",
    "ret_train_best, stats_train_best = backtest_cs_mom(\n",
    "    ret_clean,\n",
    "    lookback=best_lookback,\n",
    "    n_long=best_n_long,\n",
    "    n_short=best_n_short,\n",
    "    cost_bps=0.001,\n",
    "    start_date=train_start,\n",
    "    end_date=train_end,\n",
    "    name=\"BEST_TRAIN\"\n",
    ")\n",
    "\n",
    "# 8.3 Run the SAME PARAMETERS on TEST window (OUT-OF-SAMPLE)\n",
    "ret_test_best, stats_test_best = backtest_cs_mom(\n",
    "    ret_clean,\n",
    "    lookback=best_lookback,\n",
    "    n_long=best_n_long,\n",
    "    n_short=best_n_short,\n",
    "    cost_bps=0.001,\n",
    "    start_date=test_start,\n",
    "    end_date=test_end,\n",
    "    name=\"BEST_TEST\"\n",
    ")\n",
    "\n",
    "# 8.4 Full-sample for reference (NOT used for tuning)\n",
    "ret_full_best, stats_full_best = backtest_cs_mom(\n",
    "    ret_clean,\n",
    "    lookback=best_lookback,\n",
    "    n_long=best_n_long,\n",
    "    n_short=best_n_short,\n",
    "    cost_bps=0.001,\n",
    "    start_date=train_start,\n",
    "    end_date=test_end,\n",
    "    name=\"BEST_FULL\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca50f27-4e85-4696-b282-1b9762d701af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
